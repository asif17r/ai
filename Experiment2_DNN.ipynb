{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c272f54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment-2: Implement a simple deep neural network (DNN) for solving the polynomial equation\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate training samples\n",
    "x = np.linspace(-20, 20, 1000)\n",
    "y = 5 * x**3 - 10 * x**2 - 20 * x + 10\n",
    "\n",
    "# Normalize the data\n",
    "x_normalized = (x - np.min(x)) / (np.max(x) - np.min(x)) * 2 - 1\n",
    "y_normalized = (y - np.min(y)) / (np.max(y) - np.min(y)) * 2 - 1\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_size = int(0.9 * len(x))\n",
    "val_size = int(0.05 * len(x))\n",
    "test_size = len(x) - train_size - val_size\n",
    "\n",
    "x_train, y_train = x_normalized[:train_size], y_normalized[:train_size]\n",
    "x_val, y_val = x_normalized[train_size:train_size + val_size], y_normalized[train_size:train_size + val_size]\n",
    "x_test, y_test = x_normalized[train_size + val_size:], y_normalized[train_size + val_size:]\n",
    "\n",
    "# Define the DNN model\n",
    "def create_dnn_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(32, activation='relu', input_shape=(1,)),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Compile and train the model\n",
    "model = create_dnn_model()\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "history = model.fit(x_train, y_train, epochs=50, validation_data=(x_val, y_val))\n",
    "\n",
    "# Plot training vs validation accuracy and error\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.legend()\n",
    "\n",
    "# Plot error\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training vs Validation Error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
